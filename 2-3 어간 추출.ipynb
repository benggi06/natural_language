{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a2f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 표제어 추출(Lemmatization): 표제어란 한글로 기본 사전형 단어 정도의 의미를 가짐\n",
    "#     표제어 추출은 단어들로 부터 표제어를 찾는 과정, 다른 형태를 지닌\n",
    "#     단어들의 뿌리를 찾아 단어의 개수를 줄일 수 있는지 판단\n",
    "#     Ex) am are is 의 뿌리는 be 임 (be 가 표제어)\n",
    "    \n",
    "#     표제어 추출을하는 섬세한 방법은 형태학(morphology)적 파싱을 진행\n",
    "#     형태학이란 형태소로 단어를 만들어가는 학문 형태소의 종류로 \n",
    "#     어간(stem), 접사(affix)가 있음\n",
    "    \n",
    "#     형태학적 파싱은 이 두 구성요소를 분리하는 작업\n",
    "#     Ex) cats -> cat(어간) + -s(접사)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c19995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "#NLTK의 표제어추출 도구 WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print('표제어 추출 전 :',words)\n",
    "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47493fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has-> ha, dies -> dy 로 오변환 된 이유는 표제어 추출기가 본래 단어의\n",
    "# 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d1e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('dies','v')#동사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a28772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('watched','v')#동사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10077a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has','v')#동사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee24d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표제어 추출은 문맥을 고려해 수행결과가 단어의 품사 정보를 보존\n",
    "# 하지만 어간 추출은 보존 X 정확히는 어간 추출 결과는 사전에 존재하지\n",
    "# 않는 단어일 경우가 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902ed684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 어간 추출(stemming): 형태학적 분석을 단순화한 버전이라 볼수 있고\n",
    "#     정해진 규칙만 보고 단어의 어미를 자르는 어림짐작 작업이라 볼 수\n",
    "#     있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975633c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "\u001b어간 추출 후 ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize #토큰화 모듈\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "sentence =  \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "tokenized_sentence = word_tokenize(sentence)# 토큰화\n",
    "\n",
    "print('어간 추출 전', tokenized_sentence)\n",
    "print('어간 추출 후', [stemmer.stem(word) for word in tokenized_sentence])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3bdc110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#대소문자 변경됨 \n",
    "# 규칙 기바의 접근을 하므로 결과에 사전에 없는 단어도 포함됨\n",
    "# 포터 알고리즘은 이 규칙을 가짐\n",
    "# ALIZE → AL\n",
    "# ANCE → 제거\n",
    "# ICAL → IC\n",
    "# Ex) \n",
    "# formalize -> formal\n",
    "# allowance -> allow\n",
    "# electricical -> electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919c86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stemming ['formalize', 'allowance', 'electricical']\n",
      "\n",
      "after stemming ['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "words = ['formalize', 'allowance', 'electricical']\n",
    "print('before stemming', words)\n",
    "print()\n",
    "print('after stemming', [stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f4ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 어간 추출 속도는 표제어 추출보다 빠름, 포터 어간 추출기가\n",
    "# 영어 자연어 처리에 가장 준수한 선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eca4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stemmer ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting'] \n",
      "\n",
      "after porter_stemmer ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start'] \n",
      "\n",
      "after lancaster_stemmer ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmmer = LancasterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print('before stemmer', words,'\\n')\n",
    "print('after porter_stemmer', [porter_stemmer.stem(w) for w in words],'\\n')\n",
    "print('after lancaster_stemmer', [lancaster_stemmmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7659b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포터와 랭커스터는 다른 알고리즘을 사용하기에 결과 다름\n",
    "# 이런 규칙에 기반한 알고리즘은 종종 제대로 된 일반화 수행이 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5c9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex) \n",
    "# organization: 조직\n",
    "# organ: 오르간\n",
    "\n",
    "# 두 단어에 어간추출을 하면 동일하게 organ이 추출됨 이는 의미가 동일한\n",
    "# 경우에만 같은단어를 얻기원하는 정규화 목적에 부합 x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28172c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 한국어에서 어간 추출: 한국어는 5언 9품사 구조 가짐\n",
    "# 언\t품사\n",
    "# 체언\t명사, 대명사, 수사\n",
    "# 수식언\t관형사, 부사\n",
    "# 관계언\t조사\n",
    "# 독립언\t감탄사\n",
    "# 용언\t동사, 형용사\n",
    "\n",
    "# (1) 활용:\n",
    "#     어간이 어미를 가짐\n",
    "#     어간: 용언 활용시 원칙적으로 모양이 변하지 않는 부분 가끔 \n",
    "#         바뀌기도 함\n",
    "#     어미: 용언의 어간 뒤에 붙어 변하는 부분 여러 문법적 기능 수행\n",
    "        \n",
    "# (2) 규칙 활용: \n",
    "#     어간이 어미를 취할때 어간의 모습이 일정\n",
    "#     Ex) 잡(어간)+다(어미)\n",
    "#     이때 활용전 활용후 모습이 동일하므로 규칙 기반으로 분리하면 \n",
    "#     어간추출이 됨\n",
    "    \n",
    "# (3) 불규칙 활용:\n",
    "#     어간이 어미를 취할때 어간이 바뀌거나 어미가 특수한 경우\n",
    "#     예를 들어 ‘듣-, 돕-, 곱-, 잇-, 오르-, 노랗-’ 등이 ‘듣/들-, \n",
    "#     돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라-’와 같이 어간의 \n",
    "#     형식이 달라지는 일이 있거나 ‘오르+ 아/어→올라, 하+아/어→하여\n",
    "#     이르+아/어→이르러, 푸르+아/어→푸르러’와 같이 일반적인 어미가\n",
    "#     아닌 특수한 어미를 취하는 경우 불규칙활용을 하는 예에 속합니다.\n",
    "    \n",
    "#     어간이 바뀌므로 단순 분리만으로 추출이 안되고 좀더 복잡한 규칙 필요\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
